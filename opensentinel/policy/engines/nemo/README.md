# NeMo Guardrails Policy Engine

> NVIDIA NeMo Guardrails integration for input/output filtering, jailbreak detection, and content moderation.

## Overview

The NeMo engine wraps NVIDIA's [NeMo Guardrails](https://github.com/NVIDIA/NeMo-Guardrails) as a Open Sentinel `PolicyEngine`. It provides comprehensive content safety through NeMo's rail system â€” running each request and response through configurable input/output rails for jailbreak detection, PII filtering, toxicity checks, and hallucination detection.

**Key characteristics:**
- ğŸ›¡ï¸ **Content safety** â€” Jailbreak detection, toxicity filtering, PII masking
- ğŸ”„ **Input + Output rails** â€” Bi-directional filtering (pre-call and post-call)
- ğŸ”Œ **Colang integration** â€” Programmable dialog flows via NeMo's Colang language
- ğŸŒ‰ **Open Sentinel bridge** â€” Custom NeMo actions for logging violations and requesting interventions
- âš–ï¸ **Fail-open/closed** â€” Configurable behavior on evaluation errors

```
Request â”€â”€â–º evaluate_request() â”€â”€â–º NeMo Input Rails â”€â”€â–º ALLOW / DENY / MODIFY
                                       â”‚
Response â”€â”€â–º evaluate_response() â”€â”€â–º NeMo Output Rails â”€â”€â–º ALLOW / DENY
                                       â”‚
                                  Blocked response?
                                  â”œâ”€â”€ Yes â†’ PolicyDecision.DENY + violation
                                  â””â”€â”€ No  â†’ PolicyDecision.ALLOW
```

## Architecture

### Module Map

```
nemo/
â”œâ”€â”€ __init__.py    # Package exports
â””â”€â”€ engine.py      # NemoGuardrailsPolicyEngine â€” single-file implementation
```

The NeMo engine is intentionally compact â€” most of the heavy lifting is done by the `nemoguardrails` library itself. The engine acts as an adapter between NeMo's API and Open Sentinel' `PolicyEngine` protocol.

### How It Works

1. **Initialize**: Load a `RailsConfig` (from directory or dict) and create `LLMRails`
2. **Evaluate request**: Pass messages through NeMo's `generate_async` â†’ check if response is blocked
3. **Evaluate response**: Append assistant message to conversation â†’ run through output rails â†’ check
4. **Detect blocks**: Compare NeMo's output against known blocked-response markers

---

## Configuration

### Prerequisites

```bash
pip install 'open-sentinel[nemo]'
# or
pip install nemoguardrails
```

### Initialization

```python
from opensentinel.policy.engines.nemo import NemoGuardrailsPolicyEngine

engine = NemoGuardrailsPolicyEngine()

# Option 1: From config directory (contains config.yml + Colang files)
await engine.initialize({
    "config_path": "./nemo_config/"
})

# Option 2: From dict
await engine.initialize({
    "config": {
        "models": [{"type": "main", "engine": "openai", "model": "gpt-4o-mini"}],
        "rails": {"input": {"flows": ["self check input"]}}
    }
})
```

### Configuration Parameters

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `config_path` | `str` | â€” | Path to NeMo config directory (must contain `config.yml`) |
| `config` | `dict` | â€” | Alternative: `RailsConfig` parameters as dict |
| `custom_actions` | `dict` | `{}` | Custom action functions to register with NeMo |
| `rails` | `list` | `["input", "output"]` | Which rails to enable |
| `fail_closed` | `bool` | `False` | If `True`, block on evaluation errors; if `False`, fail open |

### NeMo Config Directory Structure

```
nemo_config/
â”œâ”€â”€ config.yml          # Main NeMo configuration
â”œâ”€â”€ rails/
â”‚   â”œâ”€â”€ input.co        # Input rail Colang flows
â”‚   â””â”€â”€ output.co       # Output rail Colang flows
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ prompts.yml     # Custom prompts
â””â”€â”€ actions/
    â””â”€â”€ custom.py       # Custom Python actions
```

---

## Blocked Response Detection

NeMo doesn't always return a structured "blocked" signal â€” it often generates a natural language refusal. The engine detects blocks by matching the response against known refusal markers:

```python
BLOCKED_MARKERS = [
    "i cannot",
    "i'm not able to",
    "i am not able to",
    "refuse to",
    "[blocked]",
    "i can't help with",
    "i'm unable to",
    "sorry, but i can't",
]
```

If any marker is found (case-insensitive) in NeMo's output, the response is treated as blocked.

---

## Evaluation Flow

### `evaluate_request(session_id, request_data, context)`

Processes the request through NeMo's **input rails**:

1. Skip if `"input"` not in enabled rails â†’ return `ALLOW`
2. Extract messages from `request_data["messages"]`
3. Call `rails.generate_async(messages=messages, ...)`
4. Check NeMo's response:
   - **Blocked** (refusal markers detected) â†’ `DENY` with `nemo_input_blocked` violation
   - **Modified** (messages changed by NeMo) â†’ `MODIFY` with sanitized messages
   - **Passed** â†’ `ALLOW`
5. On error:
   - `fail_closed=True` â†’ `DENY`
   - `fail_closed=False` â†’ `WARN` (log and pass through)

### `evaluate_response(session_id, response_data, request_data, context)`

Processes the response through NeMo's **output rails**:

1. Skip if `"output"` not in enabled rails â†’ return `ALLOW`
2. Extract response content (supports OpenAI format, dicts, LiteLLM objects)
3. Build full conversation: `original_messages + [{"role": "assistant", "content": response}]`
4. Call `rails.generate_async(messages=full_conversation, ...)`
5. Check NeMo's output:
   - **Blocked** â†’ `DENY` with `nemo_output_blocked` violation and `intervention_needed`
   - **Passed** â†’ `ALLOW`
6. On error: same fail-open/closed behavior as request evaluation

---

## Open Sentinel Bridge Actions

The engine registers two custom NeMo actions that allow Colang flows to interact with Open Sentinel:

### `sentinel_log_violation`

```colang
define flow log_violation
    $result = execute sentinel_log_violation(
        violation_name="pii_detected",
        severity="error",
        message="PII found in response"
    )
```

Logs a violation through Open Sentinel' logging system. Returns `{"logged": True, ...}`.

### `sentinel_request_intervention`

```colang
define flow request_intervention
    $result = execute sentinel_request_intervention(
        intervention_name="pii_remediation",
        context={"detected_pii": ["email", "phone"]}
    )
```

Requests a Open Sentinel intervention from within a Colang flow. Returns `{"intervention_requested": "...", "context": {...}}`.

---

## Response Content Extraction

The engine handles multiple response formats:

| Format | How Content is Extracted |
|--------|------------------------|
| `str` | Used directly |
| `dict` with `content` | `response["content"]` |
| `dict` with `choices` | `response["choices"][0]["message"]["content"]` (OpenAI format) |
| Object with `.content` | `response.content` |
| Object with `.choices` | `response.choices[0].message.content` (LiteLLM format) |

---

## Error Handling

The engine supports two failure modes:

### Fail Open (default: `fail_closed=False`)
- On evaluation error â†’ return `WARN` with violation logged
- Request/response passes through unblocked
- Appropriate for non-critical guardrails

### Fail Closed (`fail_closed=True`)
- On evaluation error â†’ return `DENY`
- Request/response is blocked
- Appropriate for safety-critical deployments

---

## Session Management

The NeMo engine maintains per-session contexts for debugging, but **NeMo itself manages conversation state internally** through `LLMRails`.

```python
# Get session context
state = await engine.get_session_state("session-123")

# Reset session
await engine.reset_session("session-123")

# Shutdown (clears all state)
await engine.shutdown()
```

---

## Public API

### `NemoGuardrailsPolicyEngine` (extends `PolicyEngine`)

| Method | Description |
|--------|-------------|
| `initialize(config)` | Load NeMo config, create `LLMRails`, register actions |
| `evaluate_request(session_id, request_data, context)` | Run input rails |
| `evaluate_response(session_id, response_data, request_data, context)` | Run output rails |
| `get_session_state(session_id)` | Get session debug context |
| `reset_session(session_id)` | Clear session context |
| `shutdown()` | Release all NeMo resources |

### Key Properties

| Property | Value |
|----------|-------|
| `name` | `"nemo:guardrails"` |
| `engine_type` | `"nemo"` |

---

## Usage with Composite Engine

The NeMo engine is commonly paired with the FSM or LLM engine via the Composite engine for defense-in-depth:

```python
from opensentinel.policy.engines.composite import CompositePolicyEngine

engine = CompositePolicyEngine()
await engine.initialize({
    "engines": [
        {
            "type": "fsm",
            "config": {"config_path": "./workflow.yaml"}
        },
        {
            "type": "nemo",
            "config": {"config_path": "./nemo_config/"}
        }
    ],
    "strategy": "all"
})
# FSM enforces workflow; NeMo catches jailbreaks and unsafe content
```

---

## Comparison with Other Engines

| Feature | NeMo Engine | FSM Engine | LLM Engine |
|---------|------------|-----------|------------|
| Focus | Content safety | Workflow enforcement | Nuanced evaluation |
| Classification | N/A (content filtering) | Tool/regex/embeddings | LLM-based |
| Stateful | Minimal | Full FSM | Full with drift |
| External deps | `nemoguardrails` | None (embeddings optional) | `litellm` |
| Latency | Medium (NeMo LLM calls) | Low (~0ms local) | Medium (LLM API) |
| Best for | Safety guardrails | Deterministic workflows | Conversational policies |
